{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3fa47c9",
   "metadata": {},
   "source": [
    "# Downstream Model (LSTM) for v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f562c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "151bb66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv(\"labeled_data_non-overlapped_labeling_fn_v2.csv\")\n",
    "\n",
    "# Split the data into non-abstained and abstained datasets\n",
    "non_abstained_data = data[data['label'] != 'ABSTAIN']\n",
    "abstained_data = data[data['label'] == 'ABSTAIN']\n",
    "\n",
    "# Extract text and labels from non-abstained data\n",
    "train_data = non_abstained_data['concatenated_title_abstract']\n",
    "y = non_abstained_data['label']\n",
    "\n",
    "# Initialize the label encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the label encoder to the labels and transform\n",
    "y_integer_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Now, one-hot encode the integer encoded labels\n",
    "y_encoded = to_categorical(y_integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d891ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "MAX_NB_WORDS = 5000\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(train_data.values)\n",
    "X = tokenizer.texts_to_sequences(train_data.values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e33d73b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = y.nunique()\n",
    "\n",
    "# Adjust the LSTM model's output layer to match the number of classes\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95daa850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels from non-abstained data to one-hot encoding\n",
    "y_encoded = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "28007953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the non-abstained data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b3b3ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/u22/harsh24/.local/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/u22/harsh24/.local/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/u22/harsh24/.local/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/u22/harsh24/.local/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/u22/harsh24/.local/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"/home/u22/harsh24/.local/lib/python3.8/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/u22/harsh24/.local/lib/python3.8/site-packages/keras/src/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/u22/harsh24/.local/lib/python3.8/site-packages/keras/src/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/u22/harsh24/.local/lib/python3.8/site-packages/keras/src/losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/u22/harsh24/.local/lib/python3.8/site-packages/keras/src/backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 995) and (None, 198) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[1;32m      3\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filel7iynmvr.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/u22/harsh24/.local/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/u22/harsh24/.local/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/u22/harsh24/.local/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/u22/harsh24/.local/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/u22/harsh24/.local/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"/home/u22/harsh24/.local/lib/python3.8/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/u22/harsh24/.local/lib/python3.8/site-packages/keras/src/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/u22/harsh24/.local/lib/python3.8/site-packages/keras/src/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/u22/harsh24/.local/lib/python3.8/site-packages/keras/src/losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/u22/harsh24/.local/lib/python3.8/site-packages/keras/src/backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 995) and (None, 198) are incompatible\n"
     ]
    }
   ],
   "source": [
    "# Train the LSTM model\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23ed406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set from non-abstained data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_test_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "876e61d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n"
     ]
    }
   ],
   "source": [
    "print(y.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed26bdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995\n"
     ]
    }
   ],
   "source": [
    "print(y_encoded.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88f3325b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: jinja2 in /home/u22/harsh24/.local/lib/python3.8/site-packages (3.1.2)\n",
      "Requirement already satisfied: nbconvert in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (6.4.1)\n",
      "Collecting nbconvert\n",
      "  Downloading nbconvert-7.9.2-py3-none-any.whl (256 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.4/256.4 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /home/u22/harsh24/.local/lib/python3.8/site-packages (from jinja2) (2.1.3)\n",
      "Requirement already satisfied: traitlets>=5.1 in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from nbconvert) (5.1.1)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /home/u22/harsh24/.local/lib/python3.8/site-packages (from nbconvert) (6.8.0)\n",
      "Requirement already satisfied: defusedxml in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from nbconvert) (0.7.1)\n",
      "Requirement already satisfied: packaging in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from nbconvert) (21.3)\n",
      "Collecting tinycss2\n",
      "  Downloading tinycss2-1.2.1-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from nbconvert) (4.9.1)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mistune<4,>=2.0.3\n",
      "  Downloading mistune-3.0.2-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 KB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nbformat>=5.7\n",
      "  Downloading nbformat-5.9.2-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.6/77.6 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nbclient>=0.5.0 in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from nbconvert) (0.5.10)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from nbconvert) (1.5.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from nbconvert) (0.1.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from nbconvert) (4.1.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from nbconvert) (2.11.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/u22/harsh24/.local/lib/python3.8/site-packages (from bleach!=5.0.0->nbconvert) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from bleach!=5.0.0->nbconvert) (0.5.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/u22/harsh24/.local/lib/python3.8/site-packages (from importlib-metadata>=3.6->nbconvert) (3.17.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.5 in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from nbclient>=0.5.0->nbconvert) (7.1.2)\n",
      "Requirement already satisfied: nest-asyncio in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from nbclient>=0.5.0->nbconvert) (1.5.4)\n",
      "Collecting fastjsonschema\n",
      "  Downloading fastjsonschema-2.18.1-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from nbformat>=5.7->nbconvert) (4.4.0)\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from packaging->nbconvert) (3.0.7)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (5.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (21.4.0)\n",
      "Requirement already satisfied: tornado>=4.1 in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from jupyter-client>=6.1.5->nbclient>=0.5.0->nbconvert) (6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/u22/harsh24/.local/lib/python3.8/site-packages (from jupyter-client>=6.1.5->nbclient>=0.5.0->nbconvert) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from jupyter-client>=6.1.5->nbclient>=0.5.0->nbconvert) (0.4)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/site-packages (from jupyter-client>=6.1.5->nbclient>=0.5.0->nbconvert) (22.3.0)\n",
      "Installing collected packages: fastjsonschema, tinycss2, soupsieve, mistune, beautifulsoup4, nbformat, nbconvert\n",
      "Successfully installed beautifulsoup4-4.12.2 fastjsonschema-2.18.1 mistune-3.0.2 nbconvert-7.9.2 nbformat-5.9.2 soupsieve-2.5 tinycss2-1.2.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/opt/ohpc/pub/apps/python/3.8.12/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade jinja2 nbconvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea424dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: Jinja2 3.1.2\n",
      "Uninstalling Jinja2-3.1.2:\n",
      "  Would remove:\n",
      "    /home/u22/harsh24/.local/lib/python3.8/site-packages/Jinja2-3.1.2.dist-info/*\n",
      "    /home/u22/harsh24/.local/lib/python3.8/site-packages/jinja2/*\n",
      "Proceed (Y/n)? ^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall jinja2 nbconvert mistune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a5c507c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43my\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f2b659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
